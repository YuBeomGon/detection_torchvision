{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitting-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.utils.data.sampler import Sampler\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "from dataset import CocoDetection, train_transforms, val_transforms, test_transforms\n",
    "from visualize import visualize\n",
    "# from rcnn_model import fasterrcnn_resnet201_fpn, FastRCNNPredictor\n",
    "from engine import evaluate\n",
    "import utils\n",
    "from models.swin import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c655d0f9-b067-43fd-b2ae-cc9953a91727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.detection.backbone_utils import swin_fpn_backbone, _validate_trainable_layers\n",
    "from ops.feature_pyramid_network import LastLevelP6P7, LastLevelMaxPool\n",
    "from models.detection.retinanet import RetinaNet\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from models.detection.anchor_utils import AnchorGenerator\n",
    "# from models.detection.backbone_utils import mobilenet_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7acde29-6e29-450f-95ca-04be2b73cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retinanet_swin_t_fpn(pretrained=False, progress=True,\n",
    "                           num_classes=91, pretrained_backbone=False, trainable_backbone_layers=None, **kwargs):\n",
    "    trainable_backbone_layers = _validate_trainable_layers(\n",
    "        pretrained or pretrained_backbone, trainable_backbone_layers, 5, 3)\n",
    "\n",
    "    if pretrained:\n",
    "        # no need to download the backbone if pretrained is set\n",
    "        pretrained_backbone = False\n",
    "        \n",
    "    anchor_sizes = ((32, 64, 128, 256, 512), ) * 5\n",
    "    aspect_ratios = ((0.5, 0.75, 1.0, 1.5, 2.0),) * len(anchor_sizes)\n",
    "    rpn_anchor_generator=AnchorGenerator(anchor_sizes, aspect_ratios)\n",
    "    \n",
    "    # skip P2 because it generates too many anchors (according to their paper)\n",
    "    backbone = swin_fpn_backbone('swin_t', pretrained_backbone, returned_layers=[2, 3, 4],\n",
    "                                   extra_blocks=LastLevelP6P7(256,256), trainable_layers=trainable_backbone_layers)\n",
    "    \n",
    "    model = RetinaNet(backbone, num_classes, anchor_generator=rpn_anchor_generator, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['retinanet_resnet50_fpn_coco'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "        overwrite_eps(model, 0.0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3db16c9-0a5a-4610-a563-d5bb08b05fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180543123/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_layers {'layer2': '0', 'layer3': '1', 'layer4': '2'}\n",
      "model is loaded to gpu\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASS = 91\n",
    "IMG_SIZE = 448*2\n",
    "model = retinanet_swin_t_fpn(pretrained=False, min_size=IMG_SIZE, max_size=IMG_SIZE, num_classes=NUM_CLASS)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "print('model is loaded to gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca06678d-92e5-4e42-aadd-dae62778c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e85dcca-de7c-4931-9573-b31c5683ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch_size\": 2, \n",
    "                          \"epochs\": 90, \n",
    "                          \"data\": 0, \n",
    "                          'lr':0.002,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0,\n",
    "                          'workers':12,\n",
    "                         'print_freq':1000,\n",
    "                         'output_dir':'../trained_model/retinanet_swin_v2_t_fpn/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d7af831-87c8-4190-bd16-e7168234bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path(args.output_dir.split('checkpoint')[0])\n",
    "path.mkdir(parents=True, exist_ok=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a03170-914b-4b1d-bcc7-3f9dfc3b39a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cbb054c-9f18-420b-9f99-e81ca82698e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from dataset import CocoDetection, train_transforms, val_transforms, test_transforms\n",
    "train_dataset = CocoDetection(root='/home/Dataset/scl/', annFile='../../data/train.json', \n",
    "                              transforms=train_transforms)\n",
    "test_dataset = CocoDetection(root='/home/Dataset/scl/', annFile='../../data/test.json', \n",
    "                              transforms=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6828ca37-77b2-49b2-a254-8228ebfdf935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[667.1875, 472.5000, 743.3125, 542.9375]]),\n",
       " 'category_id': tensor([1]),\n",
       " 'labels': tensor([1]),\n",
       " 'image_id': tensor([1]),\n",
       " 'area': tensor([5362.0547]),\n",
       " 'iscrowd': tensor([0])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, target = next(iter(train_dataset))\n",
    "target\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47c21288-37ac-405b-91b0-e5b93073d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size,\n",
    "    sampler=train_sampler, num_workers=args.workers,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=args.batch_size,\n",
    "    sampler=test_sampler, num_workers=args.workers,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02e2082-4e0a-49c3-8fea-0c7c8a38ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "optimizer = torch.optim.SGD(\n",
    "       params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 30, 45, 60, 75], \n",
    "                                                    gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f46c9f-b749-4c50-9f9e-a3d589b472f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/3098]  eta: 1:39:47  lr: 0.000004  loss: 3.0876 (3.0876)  classification: 2.3525 (2.3525)  bbox_regression: 0.7351 (0.7351)  time: 1.9328  data: 1.0108  max mem: 7460\n",
      "Epoch: [0]  [1000/3098]  eta: 0:18:23  lr: 0.002000  loss: 1.6415 (2.1396)  classification: 1.0110 (1.5201)  bbox_regression: 0.5783 (0.6195)  time: 0.5292  data: 0.0047  max mem: 7789\n",
      "Epoch: [0]  [2000/3098]  eta: 0:09:39  lr: 0.002000  loss: 1.4683 (1.9623)  classification: 0.9360 (1.3566)  bbox_regression: 0.5172 (0.6057)  time: 0.5285  data: 0.0048  max mem: 7789\n"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(args.epochs):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch, args.print_freq)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if epoch > 60 and epoch % 5 == 0 :\n",
    "        if args.output_dir:\n",
    "            checkpoint = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                'args': args,\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(args.output_dir, 'model_{}.pth'.format(epoch)))\n",
    "            utils.save_on_master(\n",
    "                checkpoint,\n",
    "                os.path.join(args.output_dir, 'checkpoint.pth'))\n",
    "\n",
    "    if epoch > 5 and epoch % 5 == 0 :\n",
    "        # evaluate after every epoch\n",
    "        evaluate(model, test_loader, device=device)    \n",
    "print('total time is {}'.format(time.time() - start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20ad5b-dbc4-4b7c-880a-800df4e96e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae7c63-dee7-46a1-916d-a8e13e6cf20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b51ded-faf6-4950-9f9a-2de14fddf56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
